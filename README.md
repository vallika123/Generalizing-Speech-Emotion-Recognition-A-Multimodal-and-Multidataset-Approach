# Generalizing-Speech-Emotion-Recognition-A-Multimodal-and-Multidataset-Approach

Problem Statement:
Emotion Detection from Speech: The task involves accurately predicting emotions from speech, which is challenging due to factors such as speaker diversity, poor audio quality, speaker diarization issues, and the lack of inclusive and complex datasets.

Tools Used:
Datasets: Combined multiple datasets to enhance generalizability.
Feature Extraction: Employed various feature extraction techniques.
Data Augmentation: Applied techniques like noise addition and time stretching to improve the modelâ€™s robustness.
Machine Learning Models: Used traditional machine learning algorithms through ensemble learning, combining Support Vector Machines (SVM) and Random Forest (RF).

Outcome:
Accuracy: Achieved an overall accuracy of 81% in emotion detection.
Emotion Classification: Approximately 80% accuracy was observed across each emotion (happy, anger, sadness, fear, neutral, and disgust) based on the confusion matrix.
